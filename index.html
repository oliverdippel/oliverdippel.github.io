<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Oliver  Dippel</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
      margin: 0;
      padding: 0;
      background: #ffffff;
      color: #222;
      line-height: 1.6;
    }

    a {
      color: #1a0dab;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    .page {
      max-width: 900px;
      margin: 30px auto 60px auto;
      padding: 0 16px;
    }

    /* Name at top */
    h1.name {
      text-align: center;
      font-size: 2.2rem;
      font-weight: 500;
      margin-bottom: 24px;
    }

    /* Intro section: text + photo */
    .intro {
      display: flex;
      align-items: flex-start;
      justify-content: space-between;
      gap: 32px;
    }

    .intro-text {
      flex: 2;
      font-size: 0.98rem;
    }

    .intro-text p {
      margin-top: 0;
      margin-bottom: 10px;
    }

    .links {
      margin-top: 8px;
      text-align: center;
      font-size: 0.9rem;
    }

    .links a {
      margin: 0 4px;
    }

    .photo-wrapper {
      flex: 1;
      display: flex;
      justify-content: center;
    }

    .photo-wrapper img {
      max-width: 260px;
      width: 100%;
      height: auto;
      border-radius: 4px;
    }

    hr {
      border: none;
      border-top: 1px solid #e0e0e0;
      margin: 28px 0 18px 0;
    }

    h2.section-title {
      font-size: 1.4rem;
      font-weight: 500;
      margin: 0 0 8px 0;
    }

    .research p {
      margin-top: 0;
      margin-bottom: 10px;
      font-size: 0.98rem;
    }

    /* Publications */
    .pub-list {
      margin-top: 10px;
      font-size: 0.94rem;
    }

    .pub {
      margin-bottom: 18px;
    }

    .pub-title {
      font-weight: 600;
      display: block;
    }

    .pub-authors {
      font-style: italic;
      margin-top: 2px;
    }

    .pub-venue {
      margin-top: 2px;
      color: #555;
    }

    .pub-links a {
      margin-right: 8px;
      font-size: 0.9rem;
    }

    .pub-teaser {
      margin-top: 4px;
    }

    /* Simple thumbnails (optional) */
    .pub-with-thumb {
      display: grid;
      grid-template-columns: 80px 1fr;
      gap: 10px;
      align-items: start;
    }

    .pub-thumb {
      width: 80px;
      height: 80px;
      background: #f2f2f2;
      border: 1px solid #e0e0e0;
      border-radius: 2px;
      object-fit: cover;
    }

    @media (max-width: 800px) {
      .intro {
        flex-direction: column-reverse;
        align-items: center;
      }

      .intro-text {
        width: 100%;
      }

      .photo-wrapper {
        width: 100%;
      }
    }

    @media (max-width: 600px) {
      .pub-with-thumb {
        grid-template-columns: 1fr;
      }
    }
  </style>
</head>
<body>
  <div class="page">

    <!-- HEADER: name -->
    <h1 class="name">Oliver Dippel</h1>

    <!-- INTRO: left text, right photo -->
    <div class="intro">
      <div class="intro-text">
        <!-- Replace these paragraphs with your own bio -->
        <p>
          I am a Ph.D. candidate in Artificial Intelligence at the 
          <a href="https://www.liverpool.ac.uk" target="_blank" rel="noopener noreferrer">University of Liverpool</a>, working on reinforcement learning and
          decision-making in complex environments. I am also affiliated with the
          <a href="https://www.liverpool.ac.uk/doctoral-training/distributed-algorithms/" target="_blank" rel="noopener noreferrer">Centre for Doctoral Training in Distributed Algorithms</a>.
        </p>
        <p>
          My research focuses on agents that can acquire new skills over time, generalize beyond
          their training distribution, and interact safely with humans and tools. I am particularly
          interested in combining large language models with
          reinforcement learning to build agents that can plan and reason.
        </p>
        <p>
         During my Ph.D., I briefly worked at ZeroAI, a research-driven start-up founded by Ph.D. students, 
         where I contributed to developing and evaluating autonomous driving systems focused on safety, robustness, 
         and interpretable decision-making.
        </p>
        <p>
          Prior to my Ph.D., I interned at
          <a href="https://www.novartis.com">Novartis</a> where I worked in the Early Development Biostatistics department developing internal software tools to streamline and support scientific workflows.
        </p>
        <p>
         I earned an M.Sc. in Applied Statistics and a B.Sc. in Economics at the 
         <a href="https://www.uni-goettingen.de" target="_blank" rel="noopener noreferrer">Georg-August-University Goettingen</a>.
        </p>

      </div>

      <div class="photo-wrapper">
        <!-- Put your own portrait at img/profile.jpg -->
        <img src="img/profile.jpg" alt="Portrait of Your Name">
      </div>
    </div>

    <!-- LINKS UNDER INTRO -->
    <div class="links">
      <a href="mailto:o.dippel91@gmail.com">Email</a> /
      <a href="files/Oliver_Dippel_CV.pdf" target="_blank" rel="noopener noreferrer">CV</a> /
      <a href="https://github.com/oliverdippel" target="_blank" rel="noopener noreferrer">GitHub</a> /
      <a href="https://www.linkedin.com/in/oliver-dippel-875707192/" target="_blank" rel="noopener noreferrer">LinkedIn</a>
    </div>

    <!-- RESEARCH SECTION -->
    <hr>
    <h2 class="section-title">Research</h2>

<div class="research">
  <p>
    My research focuses on developing autonomous learning systems that operate robustly in complex and uncertain environments. 
    I am interested in agents that go beyond solving a single predefined task, and instead learn how to reason, adapt, and improve 
    over time through interaction.
  </p>

  <p>
    At the core of my work lies the intersection of reinforcement learning, sequential decision-making, and large-scale models. 
    I study how artificial agents can understand their surroundings, plan over extended time horizons, and generalize their 
    behavior beyond the data or situations they were explicitly trained on.
  </p>

  <p>
  A long-term motivation is the pursuit of artificial general intelligence (AGI)â€”systems 
  capable of flexible reasoning, continual learning, and adaptation across diverse domains without retraining from scratch. 
  I aim to contribute to this vision by developing agents that can autonomously acquire knowledge, refine their decision-making 
  processes through experience, and extend their competencies to entirely new tasks and environments.
</p>


  <p>
    Ultimately, my goal is to bridge the gap between specialized AI systems and genuinely open-ended learners that can address 
    a wide range of real-world challenges in a scalable and reliable manner.
  </p>
</div>


    <!-- PUBLICATIONS SECTION -->
    <div class="pub-list">

      <!-- Example publication with thumbnail -->
      <div class="pub pub-with-thumb">
        <img class="pub-thumb" src="img/model.png" alt="Thumbnail for Paper 1">
        <div>
          <span class="pub-title">
            <a href="https://arxiv.org/abs/2511.10251">Heuristic Transformer: Belief Augmented In-Context Reinforcement Learning</a>
          </span>
          <div class="pub-authors">
            Oliver Dippel, Alexei Lisitsa, Bei Peng
          </div>
        </div>
      </div>

       <div class="pub pub-with-thumb">
        <img class="pub-thumb" src="img/model_blau_lambda.png" alt="Thumbnail for Paper 1">
        <div>
          <span class="pub-title">
            <a href="https://link.springer.com/chapter/10.1007/978-3-031-77915-2_15">Contextual Transformers for Goal-Oriented Reinforcement Learning</a>
          </span>
          <div class="pub-authors">
            Oliver Dippel, Alexei Lisitsa, Bei Peng
          </div>
        </div>
      </div>

      <!-- Example publication without thumbnail -->
      <div class="pub">
        <span class="pub-title">
          <a href="https://link.springer.com/chapter/10.1007/978-3-031-47994-6_30">Deep Reinforcement Learning for Continuous Control of Material Thickness</a>
        </span>
        <div class="pub-authors">
          Oliver Dippel, Alexei Lisitsa, Bei Peng
        </div>
      </div>

      <!-- Add more .pub blocks as needed -->

    </div>

  </div>
</body>
</html>
